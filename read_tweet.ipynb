{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Twitter Feed Data and Sentiments into iguazio Stream & Time-Series DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization \n",
    "install packages and set environment variables.<br>\n",
    "need to fill the following environment variables with real credentials.\n",
    "\n",
    "```\n",
    "    V3IO_PASSWORD = <V3IO-Password>\n",
    "    V3IO_USER = <V3IO-Username>\n",
    "    V3IO_ADDRESS = <address of V3IO API end point>\n",
    "    FRAMESD_URL = <V3IO Framesd URL (Columnar & TSDB API)>\n",
    "    \n",
    "    # Twitter credentials\n",
    "    app_key = <..>\n",
    "    app_secret = <..>\n",
    "    oauth_token = <..>\n",
    "    oauth_token_secret = <..>\n",
    "\n",
    "```\n",
    "> note: in nuclio environment variables and build dependencies are specified in the configuration tab, for notebooks they can be initialized from a file as implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "!pip install textblob\n",
    "!pip install twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize nuclio emulation (this section will be ignored by nuclio nbconvert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from nuclio import Context, Event\n",
    "from v3io import env_fromfile\n",
    "env_fromfile('tweet_env.txt')\n",
    "context = Context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter stream handling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import json\n",
    "import re\n",
    "import v3io\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import v3io_frames as v3f\n",
    "import pandas as pd\n",
    "\n",
    "oauth = {\n",
    "    'app_key' : os.getenv('app_key'),\n",
    "    'app_secret' : os.getenv('app_secret'),  \n",
    "    'oauth_token' : os.getenv('oauth_token'), \n",
    "    'oauth_token_secret' : os.getenv('oauth_token_secret'),\n",
    "}\n",
    "lastText = ''\n",
    "\n",
    "# initialize iguazio v3io APIs\n",
    "v3 = v3io.v3io(os.getenv('V3IO_ADDRESS'),os.getenv('V3IO_USER'),os.getenv('V3IO_PASSWORD'), 'bigdata')\n",
    "client = v3f.Client()\n",
    "\n",
    "# Twitter stream handler  \n",
    "class MyStreamer(TwythonStreamer):\n",
    "    def __init__(self, context, name, **kw):\n",
    "        self.name = name\n",
    "        self.context = context\n",
    "        TwythonStreamer.__init__(self, **kw)\n",
    "        \n",
    "    def start(self, cb, limit=10, **kw):\n",
    "        self.cb = cb\n",
    "        self.limit = limit\n",
    "        self.statuses.filter(**kw)\n",
    "        \n",
    "    def on_success(self, data):\n",
    "        if 'text' in data:\n",
    "            record = {'text': data['text'], \n",
    "                      'user': '@'+data['user']['screen_name'],\n",
    "                      'id': data['id'],\n",
    "                      'created_at':data['created_at'],\n",
    "                     }\n",
    "            self.context.last_message = record\n",
    "            if self.cb:\n",
    "                self.cb(self.context, self.name, record)\n",
    "                \n",
    "        self.limit -= 1 \n",
    "        if self.limit <= 0 :\n",
    "            self.disconnect()\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        self.context.logger.error_with('Error in stream', status_code=status_code)\n",
    "\n",
    "def process_event(context, name, record):\n",
    "    clean = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", record['text']).split())\n",
    "        \n",
    "    # enrich the record with natural language metadata\n",
    "    blob = TextBlob(clean)\n",
    "    record['polarity'] = blob.sentiment.polarity\n",
    "    record['subjectivity'] = blob.sentiment.subjectivity\n",
    "\n",
    "    # Write the record into a iguazio straem\n",
    "    context.logger.debug_with('writing data to Stream', record=record)\n",
    "    resp = v3.putrecords('stocks_stream', [json.dumps(record)])\n",
    "        \n",
    "    # Write data to iguazio Time-Series DB\n",
    "    df = pd.DataFrame(index=[[pd.to_datetime(record['created_at'])],['GOOG']], columns=['sentiment'])\n",
    "    df['sentiment'] = [float(blob.sentiment.polarity)]\n",
    "    df.index.names=['time','symbol']\n",
    "    client.write(backend='tsdb', table='stock_metrics',dfs=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclio service initialization (init_context) and event handler implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def start_listener(context):\n",
    "    stream = MyStreamer(context, 'GOOG', **oauth)\n",
    "    stream.start(process_event, 200, track='@Google', lang='en')\n",
    "\n",
    "def handler(context, event):\n",
    "    return json.dumps(context.last_message)\n",
    "\n",
    "def init_context(context):\n",
    "    context.last_message = {}\n",
    "    t = threading.Thread(target=start_listener, args=(context,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function invocation\n",
    "the following section simulates nuclio function initialization and invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-25 23:21:12,006 nuclio (D) writing data to Stream {\"record\": {\"text\": \"RT @NextBillionFH: News via @MarketWatch: @Google touts 30 million monthly users for its mobile-payment platform in India: https://t.co/bkr\\u2026\", \"user\": \"@PickDraftDFS\", \"id\": 1055554888657190917, \"created_at\": \"Thu Oct 25 20:21:11 +0000 2018\", \"polarity\": 0.0, \"subjectivity\": 0.0}}\n",
      "2018-10-25 23:21:14,804 nuclio (D) writing data to Stream {\"record\": {\"text\": \"Hey @Google, 'tha' should be 'than' near the bottom of this page on the note. Just a heads up! https://t.co/8CQ1b7N9wd\", \"user\": \"@RoryCollinsSEO\", \"id\": 1055554898438352896, \"created_at\": \"Thu Oct 25 20:21:13 +0000 2018\", \"polarity\": 0.1, \"subjectivity\": 0.4}}\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "init_context(context)\n",
    "event = Event(body='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
